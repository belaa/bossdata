#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Licensed under a MIT style license - see LICENSE.rst

"""Query the meta data for BOSS observations.
"""

from __future__ import division,print_function

import sys, time
import os.path, posixpath
import locale, fnmatch

from astropy.utils.compat import argparse
import bossdata.meta as bdm
import bossdata.path as bdp

# Let Python figure out from OS/Env what the locale is
locale.setlocale(locale.LC_ALL, '')

env_vars = ["BOSS_LOCAL_ROOT", "BOSS_DATA_URL", "BOSS_SAS_PATH", "BOSS_REDUX_VERSION"]
# Need to de-unixfy these via... posixpath, I guess
# Blanks/None will not be set
boss_default_env = [None, None, "/sas/dr12/boss", "v5_7_0"]
quasar_default_env = [None, None, "/sas/dr12/boss", "DR12Q"]
sequels_default_env = [None, None, "/sas/dr12/boss", "v5_7_2"]

def main():
    # Initialize and parse command-line arguments.
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description = "A utility for managing disk space and the metadata DB files for BOSSDATA.")

    overall_group = parser.add_argument_group('Utility-wide Options')
    overall_group.add_argument('--verbose', action = 'store_true',
        help = 'Provide verbose output.')
    overall_group.add_argument('--catalogs', type = str, default='FULL,LITE,QUASAR', metavar='FULL|LITE|QUASAR',
        help = 'Catalog names to target, separated by commas',)
    overall_group.add_argument('--env', action = 'store_true',
        help = 'Print out the current bossdata environment settings.')
    overall_group.add_argument('--set-env', type = str, default = None, metavar="BOSS|QUASAR|SEQUELS",
        help = 'Temporarily sets environment to specified defaults.')

    db_group = parser.add_argument_group('Metadata DB Management')
    db_group.add_argument('--db-index-print', action = 'store_true',
        help = 'Dump DB indexes, after any changes.')
    db_group.add_argument('--db-index-update', type = str, default=None, metavar='INDEX_FILE',
        help = 'Update DB indexes according to the specified file.')
    db_group.add_argument('--db-index-reset', action = 'store_true',
        help = 'Delete DB indexes, leaving primary-key only.')
    db_group.add_argument('--db-compact', action = 'store_true', help = 'Attempts to shrink DB.')
    db_group.add_argument('--prune', action = 'store_true',
        help = 'Delete source data that has already been stored in catalog DB\'s.')

    file_group = parser.add_argument_group('File Management')
    file_group.add_argument('--total-files', action = 'store_true',
        help = 'Print out file space summary.')
    file_group.add_argument('-amin', type = int, default = 0, metavar = 'N',
        help = 'File was last accessed at least N minutes again.')
    file_group.add_argument('-atime', type = int, default = 0, metavar = 'N',
        help = 'File was last accessed at least N*24 hours ago.')
    file_group.add_argument('-cmin', type = int, default = 0, metavar = 'N',
        help = 'File was created at least N minutes again.')
    file_group.add_argument('-ctime', type = int, default = 0, metavar = 'N',
        help = 'File was created at least N*24 hours ago.')
    file_group.add_argument('-filename', type = str, default = None, metavar = 'SUBSTRING',
        help = 'File name substring that must be matched; filename wildcarding supported.')
    file_group.add_argument('--delete', action = 'store_true',
        help = 'Deletes files that match file criteria.')
    file_group.add_argument('--dry-run', action = 'store_true',
        help = 'Prints files that --delete would remove.')

    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    args = parser.parse_args()

    if args.set_env:
        set_env(args.set_env)
    curr_boss_env = get_env()

    # Figure out our list of catalog objects.  These will not autocreate the DB (or download any
    # files) if the DB's do not already exist.  Rather than replicate the logic of the Database
    # init function, allow for "uninitialized" Database (check bool 'initialized' instance var)
    # by passing new constructor arg "autocreate=False"
    target_catalogs = args.catalogs.split(',')

    # Anything that requires us having initialized Databse instances
    if args.db_index_print or args.db_index_reset or args.db_index_update or args.db_compact or args.prune:
        if args.verbose:
            print("Entered DB processing branch")

        dbs = []
        if "LITE" in target_catalogs:
            dbs.append( bdm.Database(lite=True, verbose=args.verbose, autocreate=False,
                allow_full_replace=False) )
        if "FULL" in target_catalogs:
            dbs.append( bdm.Database(lite=False, verbose=args.verbose, autocreate=False,
                allow_full_replace=False) )
        if "QUASAR" in target_catalogs:
            dbs.append( bdm.Database(lite=False, quasar_catalog=True,
                quasar_catalog_name=bdp.Finder.default_quasar_catalog_name,
                verbose=args.verbose, autocreate=False, allow_full_replace=False) )
        if args.verbose:
            print("DB list being used: {}".format([db.db_catalog for db in dbs]))

        # We care about order here:  It is RESET, then UPDATE, then COMPACT, then PRINT
        index_update_list = None
        for db in [d for d in dbs if d.initialized]:
            if args.db_index_reset:
                if args.verbose:
                    print("Reseting Indexes...")
                reset_indexes(db)
            if args.db_index_update:
                if args.verbose:
                    print("Updating Indexes...")
                index_update_list = update_indexes(db, index_update_list, args.db_index_update, args.verbose)
            if args.db_compact:
                if args.verbose:
                    print("Compacting DB...")
                compact_db(db)
            if args.db_index_print:
                if args.verbose:
                    print("Printing Indexes...")
                print_indexes(db)

            # Not a DB operation per se, but we only want to do this on DB's that have been
            # initialized
            if args.prune:
                if args.verbose:
                    print("Pruning files for metadata DB's...")
                prune_meta_files(db)

    # And stuff that don't need the DB's to exist
    if args.delete:
        # Once to run through what it WOULD be like...
        if args.dry_run:
            print("Delete DRY-RUN: Files that would be deleted are:")
            delete_files(curr_boss_env["BOSS_LOCAL_ROOT"], args.amin, args.atime, args.cmin,
                        args.ctime, args.filename, dry_run=True)
        #Second time to (optionally) actually do it
        if(raw_input("Are you sure you want to proceed with deleting files (y|anthing)?") == "y"):
            delete_files(args.amin, args.atime, args.cmin, args.ctime, args.filename)
        else:
            print("Abandoning file delete with no changes made.")
    if args.total_files:
        display_file_space(curr_boss_env["BOSS_LOCAL_ROOT"], args.amin, args.atime, args.cmin,
                    args.ctime, args.filename)

    if args.env:
        print_env()

    print("All done!")

# Begin actual various implementations
def display_file_space(dirpath, amin, atime, cmin, ctime, substring):
    curr_boss_env = get_env()
    file_type_data = get_file_stats(dirpath, amin, atime, cmin, ctime, substring)
    total_file_size, total_count = 0, 0

    print("File storage data:")
    print("{:15s}|{:7s}|{:20s}".format("File Type", "Count", "Total Size (kB)"))
    print("-"*15 + "|" + "-"*7 + "|" + "-"*20)
    for k,v in file_type_data.items():
        print("{:15s}|{:7s}|{:20s}".format(k,
            locale.format("%d", v[0], grouping=True),
            locale.format("%d", int(round(v[1]/1024)), grouping=True)))
        total_file_size += v[1]
        total_count += v[0]
    print("-"*15 + "|" + "-"*7 + "|" + "-"*20)
    print("{:15s}|{:7s}|{:20s}".format("TOTAL",
        locale.format("%d", total_count, grouping=True),
        locale.format("%d", int(round(total_file_size/1024)), grouping=True)))

def filter_oswalk(dirpath, amin, atime, cmin, ctime, substring):
    ret = []
    for root, dirs, files in os.walk(dirpath):
        ret_files = []
        for f in files:
            stat = os.stat(posixpath.join(root, f))
            now = time.time()
            if ((atime > 0 and stat.st_atime < now - atime*86400) or atime == 0) and \
                    ((amin > 0 and stat.st_atime < now - amin*60) or amin == 0) and \
                    ((ctime > 0 and stat.st_ctime < now - ctime*86400) or ctime == 0) and \
                    ((cmin > 0 and stat.st_ctime < now - cmin*60) or cmin == 0) and \
                    ((substring is not None and fnmatch.fnmatch(f, substring)) or substring is None):
                ret_files.append(f)
        if len(ret_files) > 0:
            ret.append((root, dirs, ret_files))
    return ret

def get_file_stats(dirpath, amin, atime, cmin, ctime, substring, in_lite=False):
    # catalog of tuples; key = file-type, tuple is (count, size)
    _metadata_files = ["spAll-v5_7_?-lite.dat", "spAll-v5_7_?.dat.gz",
        "spAll-v5_7_?.fits", "DR12Q.*"]
    catalog = {}

    tup_tree = filter_oswalk(dirpath, amin, atime, cmin, ctime, substring)
    for dirpath, dirnames, filenames in tup_tree:
        for f in filenames:
            # spec, spec-lite, frame, cframe, metadata
            filetype = "other"
            if f.startswith("spec-") and f.endswith(".fits"):
                if in_lite:
                    filetype = "spec-lite"
                else:
                    filetype = "spec"
            elif f.startswith("spPlate") and f.endswith(".fits"):
                filetype = "plate"
            elif f.startswith("spCFrame") and f.endswith(".fits"):
                filetype = "cframe"
            elif f.startswith("spFrame") and f.endswith(".fits"):
                filetype = "frame"
            elif f.endswith(".db") or len([m for m in _metadata_files if fnmatch.fnmatch(f, m)]) > 0:
                filetype = "meta"
                print("Found meta file: {}".format(f))
            count_size = catalog.setdefault(filetype, [0,0])
            count_size[0:1] = [count_size[0]+1,
                                count_size[1]+os.path.getsize(posixpath.join(dirpath, f)) ]
    return catalog

def delete_files(dirpath, amin, atime, cmin, ctime, substring, dry_run=False):
    tup_tree = filter_oswalk(dirpath, amin, atime, cmin, ctime, substring)
    for dirpath, dirnames, filenames in tup_tree:
        for f in filenames:
            if not dry_run:
                # Delete it!
                os.remove(posixpath.join(dirpath, f))
            else:
                print(posixpath.join(dirpath, f))
            # For now just leave empty directories... no harm, just clutter.

def print_env():
    boss_env = get_env()
    print("BOSSDATA Environment variables:")
    for k,v in boss_env.items():
        print("\t{:20s}\t{}".format(k,v))

# This is a bit tricky as it reuqires restarting the e.g. shell to make permanent;
# child processes can't modify the parent environment... could tell the user what
# to do, but this seems like a better job of for a set pre-made shell scripts.
def set_env(env_type):
    if env_type == "BOSS":
        paired_env_vars = zip(env_vars, boss_default_env)
    elif env_type == "QUASAR":
        paired_env_vars = zip(env_vars, quasar_default_env)
    elif env_type == "SEQUELS":
        paired_env_vars = zip(env_vars, sequels_default_env)
    else:
        print("Unrecognized environment/catalog type: {}".format(env_type))
        return
    for var_name, var_value in paired_env_vars:
        if var_value is not None and var_value != "":
            os.environ[var_name] = var_value

def get_env():
    curr_boss_env = {}
    for name in env_vars:
        curr_boss_env[name]=os.environ.get(name, None)

    return curr_boss_env

def prune_meta_files(meta_db):
    if os.path.isfile(meta_db.local_path) and meta_db.initialized:
        print("Deleting metadata file:\n\t{}".format(meta_db.local_path))
        os.remove(meta_db.local_path)

def compact_db(meta_db):
    meta_db.cursor.execute("VACUUM")

def print_indexes(meta_db):
    def _col_names(sql_str):
        return sql_str[sql_str.rindex('(')+1:sql_str.rindex(')')]

    print("INDEXES for catalog {}".format(meta_db.db_catalog))
    for row in get_indexes(meta_db):
        print("\t\"{}\" on table \"{}\" on rows ({})".format(row[0], row[1], _col_names(row[2])))
    print("")

def get_indexes(meta_db):
    return meta_db.cursor.execute("SELECT name, tbl_name, sql FROM sqlite_master "\
                    "WHERE type='index' and name not like 'sqlite_autoindex%'").fetchall()

def reset_indexes(meta_db, verbose=False):
    indexes = get_indexes(meta_db)
    cnt = len(indexes)
    for row in indexes:
        if verbose:
            print("Dropping index {}".format(row[0]))
        meta_db.cursor.execute("DROP INDEX {}".format(row[0]))
    print("Dropped {} indexes from {}".format(cnt, meta_db.db_catalog))

def update_indexes(meta_db, update_list, update_file, verbose=False):
    def _update(db_catalog, index_name, index_columns):
        if db_catalog.upper() == meta_db.db_catalog:
            print("Updating for {}:{}:{}".format(db_catalog,index_name,index_columns))
            meta_db.cursor.execute(
                "CREATE INDEX IF NOT EXISTS {} ON meta ({})".format(index_name, index_columns))

    if update_list is not None:
        for ut in update_list:
            _update(ut[0], ut[1], ut[2])
        return update_list

    new_update_list = []
    with open(update_file, 'r') as f:
        for line in f:
            linesplit = line.strip().split('.')
            if len(linesplit) != 2:
                if verbose and line.strip() != "":
                    print("Skipping invalid line in update file:\n\t{}".format(line))
                continue

            name_and_columns = linesplit[1].strip().split('=')
            if len( name_and_columns) != 2:
                if verbose:
                    print("Skipping invalid name and columns in update file:\n\t{}".format(linesplit[1]))
                continue
            new_update_list.append( (linesplit[0], name_and_columns[0], name_and_columns[1]) )

            _update(linesplit[0], name_and_columns[0], name_and_columns[1])

        return new_update_list

if __name__ == '__main__':
    main()
